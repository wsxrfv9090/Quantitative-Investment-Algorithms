{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c9c784e",
   "metadata": {},
   "source": [
    "# Use k means cluster on data to get classified labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44c0827",
   "metadata": {},
   "source": [
    "## Importing and Read & Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf4c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import global_resources as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "import kmc_torch.kmc as kmc\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28710fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files from: D:\\ImportanFiles\\Coding Related\\Repositories\\Quantitative-Investment-Algorithms\\Data\\Cluster DATA\\processed_data_final.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       000001\n",
       "1       000002\n",
       "2       000004\n",
       "3       000006\n",
       "4       000007\n",
       "         ...  \n",
       "5316    920002\n",
       "5317    920008\n",
       "5318    920016\n",
       "5319    920099\n",
       "5320    920118\n",
       "Name: 证券代码, Length: 5321, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "营业总收入",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "现金资产比率",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "应收类资产比率",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "固定资产比率",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "无形资产比率",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "金融负债比率",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "少数股东权益占比",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "市盈率（PE）1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "资产负债率",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "市值A",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "托宾Q值A",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "账面市值比A",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "资产报酬率A",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "净资产收益率（ROE）A",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "84593872-de78-47f8-9291-f73ddccb7e68",
       "rows": [
        [
         "0",
         "1.2946626956245908",
         "-0.7775533714701448",
         "-1.270995588718246",
         "-1.2976557356854617",
         "-0.6924151319411184",
         "-1.4777246139709934",
         "-0.1852084343455352",
         "-0.3301430282201608",
         "2.3230681509099944",
         "4.379344904591597",
         "-0.7330830949762621",
         "1.4217897688491343",
         "-0.3753505972199367",
         "0.1325654600998444"
        ],
        [
         "1",
         "3.324777649338099",
         "-0.7061523804539985",
         "-1.208915414277693",
         "-1.2059238395553975",
         "-0.6086361099790882",
         "-0.1886669299052278",
         "1.2083498303459983",
         "-0.3263494579588539",
         "1.446345127720443",
         "0.8585277795549883",
         "-0.8294437860279755",
         "1.9587576997677063",
         "-0.7372223994100372",
         "-0.1034709087417065"
        ],
        [
         "2",
         "-0.1518644456890343",
         "0.1332306579364755",
         "2.5735127313362924",
         "-1.2770357693181664",
         "-0.1367077788563614",
         "-1.085168760549588",
         "-0.2576931058372588",
         "-0.3708435426102636",
         "0.8404080376213153",
         "-0.0686712882394555",
         "3.6171789792056472",
         "-2.012428194460719",
         "-2.865982727727685",
         "-0.4717542158278343"
        ],
        [
         "3",
         "-0.0767113292433411",
         "-0.1654533743595854",
         "-1.251412099905233",
         "-1.2878780980387468",
         "-0.7100052775049953",
         "0.4009963469366679",
         "0.0120979290750197",
         "-0.3708435426102636",
         "1.2154744707898706",
         "-0.0530086602312792",
         "-0.6641294513231278",
         "1.1081818893931026",
         "-1.0080121420635415",
         "-0.1962608800126735"
        ],
        [
         "4",
         "-0.1506255626135589",
         "1.6711500206166403",
         "-0.8420897222039524",
         "-0.3842249183697708",
         "-0.7073610072568325",
         "0.5942829382571863",
         "0.1005005841086007",
         "0.0645762575488382",
         "0.7809907982362244",
         "-0.0686666711270763",
         "4.447951086311033",
         "-2.103008304589681",
         "-0.3563455400845509",
         "0.0015724148286425"
        ],
        [
         "5",
         "-0.1358311445480871",
         "-0.8341381511777005",
         "0.6176182224277722",
         "-1.0038212149515005",
         "-0.4339007610957194",
         "0.7915210222572601",
         "-0.0973451828206181",
         "-0.3708435426102636",
         "1.1883180905611903",
         "-0.0596136012454998",
         "-0.440207950388353",
         "0.3553439372656314",
         "-0.7014963396249241",
         "-0.1305913087992993"
        ],
        [
         "6",
         "0.0784270491050006",
         "-0.0468731166167638",
         "-0.4190022629706489",
         "0.1814090609997674",
         "-0.1453796713472363",
         "1.172562907029219",
         "1.7809731550943178",
         "-0.26579694039368",
         "0.8304430269102828",
         "-0.025346003886077",
         "-0.6414127143749616",
         "1.0151389822600734",
         "0.0467685289503661",
         "0.0599172085369222"
        ],
        [
         "7",
         "-0.147469042916441",
         "-1.1760066355472645",
         "3.163995253140431",
         "-1.289805323653468",
         "-0.6999209176765915",
         "-1.3425265488045472",
         "-0.4714456962357413",
         "-0.3708435426102636",
         "2.409853498234023",
         "-0.067201455979405",
         "-0.3951062725275869",
         "0.2386269052808046",
         "-0.909582322341954",
         "-0.8528336614627534"
        ],
        [
         "8",
         "-0.1322224411123244",
         "-0.5786301430761301",
         "-0.9658467301673488",
         "-1.2847446717770508",
         "-0.7093318919138478",
         "0.3745118433960375",
         "-0.1589562235825333",
         "-0.2773768380343224",
         "1.4277176919940928",
         "-0.0567248894222079",
         "-0.6450537850060969",
         "1.0297437594143524",
         "-0.5257749780160003",
         "-0.0230250693519048"
        ],
        [
         "9",
         "0.0341465889747015",
         "-0.3800608856007499",
         "-0.3982344965694684",
         "1.549469705407721",
         "0.5219290254411075",
         "0.6670490028512511",
         "-0.0644006485259961",
         "-0.2876014631246809",
         "0.6181767918245108",
         "-0.0451694913541805",
         "-0.7113061572701971",
         "1.317261627433645",
         "0.0786806486981057",
         "0.0798773690814014"
        ],
        [
         "10",
         "-0.1479226699607485",
         "0.3446355751518916",
         "-1.258809543970446",
         "-1.2487203775941866",
         "-0.7100052775049953",
         "-1.455916175414888",
         "-0.0734663474957333",
         "-0.3296820149904477",
         "-0.7936419912777917",
         "-0.0679028334410137",
         "-0.3041498614059603",
         "0.028679324486448",
         "0.0229367906377373",
         "0.0312649030367459"
        ],
        [
         "11",
         "-0.0246396661930894",
         "-0.4577575022411944",
         "-0.7146940642595216",
         "-0.2597504024427502",
         "-0.1898723924793972",
         "1.456646722926465",
         "-0.0088048868917232",
         "-0.3708435426102636",
         "2.1155105559892973",
         "-0.0428913973058277",
         "-0.6525122471982627",
         "1.0600205257580064",
         "-1.4754029519543044",
         "-0.8519693641945301"
        ],
        [
         "12",
         "-0.148644835214609",
         "-0.8303961728949847",
         "2.674716974794606",
         "-1.264340339044968",
         "-0.7100052775049953",
         "-1.501924537074646",
         "-0.0721457389055582",
         "1.3288862828745005",
         "-1.314892600050227",
         "-0.0684669046875097",
         "4.37507321624772",
         "-2.0960772901639486",
         "0.0141022402686826",
         "0.0196394428446943"
        ],
        [
         "13",
         "-0.0929307364448234",
         "-1.0110477595842065",
         "-1.1080029493555936",
         "0.6580267803327131",
         "0.4897871814929216",
         "0.4789611188335954",
         "-0.1819571331967661",
         "-0.2144388683868797",
         "-0.3712360037614438",
         "-0.0638666859868425",
         "-0.5741058908355279",
         "0.7645513416970103",
         "0.43249361713692",
         "0.0743889868661203"
        ],
        [
         "14",
         "-0.1434760920940323",
         "-0.429271271170069",
         "0.9537985864772924",
         "0.2688080687722587",
         "0.1490704964111062",
         "-1.5754151739736804",
         "-0.1852084343455352",
         "1.8616186564295936",
         "0.0534851802388071",
         "-0.0677966481150196",
         "2.8829082724654875",
         "-1.9041902207327528",
         "-0.000313160211561",
         "0.0500411465354754"
        ],
        [
         "15",
         "0.0185647746707163",
         "-0.5933789313526003",
         "-0.1932343297135196",
         "-0.1567381717705781",
         "-0.4894468603459824",
         "1.0330332456789706",
         "0.3570966931917216",
         "-0.1554118955771494",
         "0.5787309988482753",
         "-0.0369782394917927",
         "-0.3295696068951793",
         "0.0842368975369339",
         "0.1405440489653308",
         "0.0928285894157385"
        ],
        [
         "16",
         "-0.1203672162126971",
         "-0.6991066735973542",
         "-0.3706871700621185",
         "-1.1138954471769156",
         "-0.6844658971578164",
         "-0.1306694702157149",
         "0.0800478910697761",
         "0.0709186803645075",
         "-0.6373178994631016",
         "-0.0645010807355862",
         "1.010930674168916",
         "-1.3488607699283008",
         "0.678826738646818",
         "0.0944947729897092"
        ],
        [
         "17",
         "-0.1049880287080219",
         "-0.1044945254431791",
         "-0.5262823653595561",
         "-0.7602832396310985",
         "-0.5907174836390419",
         "0.4912432133145397",
         "-0.1852084343455352",
         "-0.2794088361883271",
         "-0.9878055071365464",
         "-0.0665756959164918",
         "-0.5514091311355764",
         "0.6875635255095441",
         "0.8553884599249938",
         "0.0902546100239405"
        ],
        [
         "18",
         "0.3279690314298396",
         "-0.4220738624911515",
         "-0.4916808636531274",
         "1.2956891324146764",
         "1.3360193570607957",
         "1.3846171088718762",
         "0.4617186537271711",
         "-0.2844779802395213",
         "1.0935883513261957",
         "0.0422209061188741",
         "-0.8243261361809695",
         "1.9267178835052676",
         "0.1687499670948318",
         "0.0692939828385642"
        ],
        [
         "19",
         "0.7400034402295779",
         "-0.3663150149270789",
         "2.798242276273361",
         "-1.2018200619352395",
         "-0.5264337957426685",
         "-0.6186708973178555",
         "0.4250764153800591",
         "-0.3042034167660505",
         "0.7985181704244982",
         "-0.0327159907681462",
         "-0.7834509491816308",
         "1.6859110653297873",
         "0.0837874497650949",
         "0.0750641600056294"
        ],
        [
         "20",
         "-0.1497713992311115",
         "-0.4333925040084663",
         "-1.153177132138988",
         "-1.2891921155033297",
         "-0.7100052775049953",
         "-1.429776140674981",
         "-0.1020472934064806",
         "-0.3708435426102636",
         "0.018485669177979",
         "-0.0561473280058248",
         "0.8235293201226708",
         "-1.2453021105080628",
         "-0.5554676863295621",
         "-0.018539045018808"
        ],
        [
         "21",
         "0.028970140160433",
         "-0.6070068117200581",
         "0.6024371568229425",
         "-0.1018728887109309",
         "-0.1586831427821012",
         "-0.7343965767147073",
         "0.3396348996078289",
         "-0.280111721078798",
         "0.2673623870330601",
         "-0.0567270286577535",
         "-0.6859897723260892",
         "1.2022685533516653",
         "0.2451580539452603",
         "0.1065760223319619"
        ],
        [
         "22",
         "0.1707988929308967",
         "-0.0331272459430943",
         "-1.2435684063140424",
         "-1.2000478229958291",
         "-0.5781695179893652",
         "0.3602302461063002",
         "2.4501311077723376",
         "0.4276138650125475",
         "1.6287301390020466",
         "0.0608855183961951",
         "-0.8251530205418571",
         "1.9318663020042464",
         "-0.1643987725539201",
         "-0.0082506924167643"
        ],
        [
         "23",
         "0.6127694376353549",
         "-0.2206728376666898",
         "0.4116397393033381",
         "-0.8096768191972025",
         "-0.4576499212127761",
         "-0.6385906965872401",
         "1.570907108675732",
         "-0.2138831119714651",
         "1.9133980454432655",
         "-0.0134407188756354",
         "-0.6332550484952806",
         "0.9828372494908524",
         "-0.3559792294594925",
         "-0.0152653063507679"
        ],
        [
         "24",
         "1.2952191736307868",
         "-0.3113736716274735",
         "1.0507720411604902",
         "-1.199832189360615",
         "-0.489709644966918",
         "0.1928698813045511",
         "0.0828788294842075",
         "-0.2501945970795293",
         "1.6869598620991717",
         "-0.0270598790908508",
         "-0.5270099624573269",
         "0.6085663797028865",
         "0.2972603534388688",
         "0.1516991482018433"
        ],
        [
         "25",
         "-0.0855384246041408",
         "-1.0586147087455766",
         "-0.4636014704032663",
         "-0.711334404437623",
         "7.599852125914669",
         "1.4088803825595697",
         "-0.1271648967891916",
         "-0.3328873382149495",
         "0.9732395591500418",
         "-0.0454387214887391",
         "-0.6473407456386779",
         "1.0389733843772146",
         "0.1454353731940525",
         "0.044564111767917"
        ],
        [
         "26",
         "-0.147810849945313",
         "0.9146046050658376",
         "-1.262782881095961",
         "-0.6776349103844064",
         "-0.7042732879608391",
         "-0.1835078167173909",
         "0.35838010153992",
         "0.0153457274720042",
         "-0.844585519476272",
         "-0.0645248645413178",
         "-0.7266677925713085",
         "1.3904301536640091",
         "-0.3564963738713397",
         "-0.0061930218963556"
        ],
        [
         "27",
         "-0.1471969321774144",
         "0.5014025527122483",
         "-0.735324523114248",
         "0.5610725070998215",
         "-0.5460769461576047",
         "1.119083135864128",
         "-0.3169530913062425",
         "-0.3708435426102636",
         "-0.3778593988714555",
         "-0.0672520692424182",
         "0.1638588696723366",
         "-0.7019856362012289",
         "-1.0093265507769889",
         "-0.0898917963000388"
        ],
        [
         "28",
         "1.886727294753744",
         "-0.177943491060001",
         "0.3719836035430668",
         "0.1727432842846223",
         "-0.1669115862251473",
         "0.1091639627289098",
         "0.7208071790227352",
         "-0.1905995988086477",
         "1.005514226635382",
         "0.0695189434627362",
         "-0.7331482381769623",
         "1.4221064141782287",
         "0.2214340540517664",
         "0.0560874449304629"
        ],
        [
         "29",
         "-0.1404410979668867",
         "-1.1308500597842204",
         "-0.1557579512532079",
         "0.1048928132544599",
         "-0.6457708617250506",
         "1.2191572615913564",
         "-0.1866183235164546",
         "-0.3708435426102636",
         "0.5256609879945997",
         "-0.0570654992792947",
         "-0.9367433233412628",
         "2.7510355867746",
         "-0.5349542913262908",
         "-0.0433975204969806"
        ],
        [
         "30",
         "-0.0919753739395776",
         "-0.589999351867534",
         "-1.1855559679371916",
         "-1.1148388443309756",
         "-0.7094468601855072",
         "0.3201412046428705",
         "-0.3181248989285109",
         "-0.3708435426102636",
         "1.963674171076804",
         "-0.0468219277965687",
         "-0.7386732501723468",
         "1.4495099173504715",
         "-0.5288347491194297",
         "-0.222948185815511"
        ],
        [
         "31",
         "-0.1131755317538002",
         "-0.5322009575818019",
         "0.234143990346473",
         "1.0417535727463223",
         "-0.6020500704168881",
         "-0.0299499604135692",
         "0.9420667782521284",
         "-0.1103317388258079",
         "-0.7824296281867636",
         "-0.0657909740648815",
         "-0.644246877893424",
         "1.0264991220915334",
         "0.0827316132575735",
         "0.0343741037128046"
        ],
        [
         "32",
         "-0.0803902367618624",
         "-0.5337179758045245",
         "-1.1732154521996307",
         "2.094126575201642",
         "-0.6452288684443692",
         "-0.2118176089607017",
         "-0.1365728379851152",
         "-0.331545141972248",
         "0.9787582879456672",
         "-0.0580087362393352",
         "-0.3556598930636054",
         "0.1436919445763964",
         "0.9279179636865658",
         "0.25782237054715"
        ],
        [
         "33",
         "0.0834931075174828",
         "-0.6815766852458924",
         "1.5596423900409824",
         "0.1703241444395704",
         "-0.281222896332136",
         "-0.0202612804668027",
         "-0.1542764331418565",
         "-0.2329615181213388",
         "0.9651847006076364",
         "-0.0538746246077897",
         "-0.5104331893191548",
         "0.5569805554716586",
         "-0.3508077853410202",
         "0.0216895483999544"
        ],
        [
         "34",
         "0.2267394507996601",
         "-0.4703656092478226",
         "-0.3892923426066462",
         "2.542529981077115",
         "-0.2251348038011917",
         "1.203434438514687",
         "0.0432531317305591",
         "-0.3708435426102636",
         "1.0374298775685462",
         "-0.0131073757295666",
         "-0.7963397485841636",
         "1.7590717731569638",
         "-0.4934103569078943",
         "-0.0513785587287129"
        ],
        [
         "35",
         "-0.1023501183179866",
         "-0.7302224029211989",
         "-0.5584037495081586",
         "-0.938982876263226",
         "-0.546257610584498",
         "0.6713647613890427",
         "-0.1557272425789502",
         "-0.2601815669511668",
         "0.6464056189334089",
         "-0.061778293637882",
         "-0.8710277310509321",
         "2.236662841067948",
         "-0.1985087560520105",
         "0.0262531136258241"
        ],
        [
         "36",
         "-0.1447972332930976",
         "-1.1426659461634268",
         "-1.0081717813618214",
         "-1.2282890906577029",
         "-0.6535558561202661",
         "1.1404995926814805",
         "-0.3433913032791286",
         "-0.3708435426102636",
         "2.3417830393862347",
         "-0.062187791019636",
         "-0.5290441674711912",
         "0.6150087439293993",
         "0.0302199077712546",
         "-0.740607403483845"
        ],
        [
         "37",
         "-0.1333954945114652",
         "0.2357473782764664",
         "-0.634437803357109",
         "-0.8288682127312075",
         "-0.6464442473161981",
         "-0.3109098006352949",
         "0.534876649598674",
         "0.1682928191515033",
         "0.4567113988716113",
         "-0.0622491822014909",
         "0.187251358755766",
         "-0.7282554709112811",
         "-0.0362977922025954",
         "0.0154295397395199"
        ],
        [
         "38",
         "0.2344261361924167",
         "0.3284961868379256",
         "-1.2062379171218385",
         "1.0968951364010864",
         "-0.0427951249495005",
         "1.332808209360866",
         "-0.0021348835052895",
         "0.2497179790564665",
         "0.5113463536706685",
         "-0.0528309937540396",
         "-0.8671286933450241",
         "2.209196790670206",
         "-1.9785198216301816",
         "-0.3012266626902503"
        ],
        [
         "39",
         "0.5700799798817348",
         "-0.5560012879205164",
         "-1.1225060589498066",
         "1.258606885709047",
         "1.194871167540762",
         "1.71611487751229",
         "0.5430904630271429",
         "-0.2452417320920341",
         "0.9566189338948272",
         "-0.0329107064467421",
         "-0.6701556316758991",
         "1.1336581561796222",
         "0.2234379886476765",
         "0.0874196393345171"
        ],
        [
         "40",
         "-0.0940657717350285",
         "-0.6258599770768946",
         "-1.159295899677848",
         "-0.6348788036522194",
         "0.3731436578751327",
         "1.295174003029024",
         "0.601572963438813",
         "-0.2444352041208033",
         "0.9438830518452072",
         "-0.0515866270437104",
         "-0.5751898736951788",
         "0.7683159028317993",
         "0.2350306425465832",
         "0.0876976518037268"
        ],
        [
         "41",
         "0.1044220334309209",
         "0.2873007142119904",
         "1.6208987192028108",
         "-1.195485823900842",
         "-0.5537141242035457",
         "1.4668620046030725",
         "0.2239309869875017",
         "0.0064229889047495",
         "0.4721767272730294",
         "-0.0387733588071242",
         "0.4919929887832197",
         "-1.0158358861560737",
         "0.2582374980282277",
         "0.0536307224984678"
        ],
        [
         "42",
         "1.2710738919332984",
         "0.1462854425309047",
         "-0.3753985352498235",
         "-0.8296027148011537",
         "-0.0864666441412359",
         "0.4108829974585625",
         "-0.168832887827364",
         "-0.2566001397656247",
         "1.0417702956288253",
         "0.1433454017707158",
         "-0.4151252123907563",
         "0.2893018855406868",
         "0.3475095521233582",
         "0.1836876033325353"
        ],
        [
         "43",
         "0.0702821022344041",
         "-0.1102254831734648",
         "0.1867042330465859",
         "-0.5184703333924054",
         "0.2974781110844878",
         "0.1505239752846616",
         "0.1264663530083815",
         "-0.2897099643496271",
         "0.8281554470842393",
         "-0.0504744773973057",
         "-0.669260129810274",
         "1.129850593827302",
         "0.2752817159353615",
         "0.1307687808770613"
        ],
        [
         "44",
         "-0.0011401496630588",
         "-0.1423188464630648",
         "0.2689943619808506",
         "-0.4605659637864673",
         "-0.3605017316606439",
         "0.8530859117105806",
         "0.1504753891801846",
         "-0.3708435426102636",
         "0.9253660827502952",
         "-0.0270052176145058",
         "-0.1883990795218365",
         "-0.1983319212646612",
         "-0.8529334615608553",
         "-0.1145233228237549"
        ],
        [
         "45",
         "-0.1445577587534903",
         "-1.0872526416389745",
         "-0.3241828204224498",
         "-1.198066688972304",
         "-0.3367032994271635",
         "0.2015766271986827",
         "1.1618755680444277",
         "-0.3255141754541132",
         "1.5374893042099909",
         "-0.0652403763703961",
         "-0.0799729991244408",
         "-0.3788393048564276",
         "-0.9435199243694288",
         "-0.1767035538623554"
        ],
        [
         "46",
         "0.3108109987172863",
         "-0.4443234630910838",
         "-1.2360079095374146",
         "-0.8724194684932445",
         "-0.1668294660311049",
         "0.4259723146948224",
         "0.8337991940029562",
         "-0.3708435426102636",
         "1.6205325943940334",
         "0.1686721854218769",
         "-0.8214902355104884",
         "1.909161659147701",
         "-0.5433363403349791",
         "-0.0905026672357853"
        ],
        [
         "47",
         "-0.0970931534369525",
         "-0.3255830756469756",
         "0.9185534556468596",
         "-0.36495266222256",
         "-0.5036865019929304",
         "0.6535949225655493",
         "0.6524926546566069",
         "-0.3708435426102636",
         "1.3608669688684392",
         "-0.0623686156900453",
         "-0.5185691407986025",
         "0.5820932665099587",
         "-0.1585808979206387",
         "0.0154219747743713"
        ],
        [
         "48",
         "0.2352590205946217",
         "-0.9714030166970544",
         "3.673783846237835",
         "-1.094663622336307",
         "-0.5164315561083072",
         "0.0275763293071384",
         "0.8397586727676334",
         "-0.3708435426102636",
         "2.1001004609035983",
         "-0.0429695907325663",
         "-0.6199293553600521",
         "0.9312709712675936",
         "-0.0013689967190803",
         "0.0361670004530138"
        ],
        [
         "49",
         "-0.1433672253667434",
         "0.4104657381390404",
         "-1.2361967074137887",
         "0.2729320620457178",
         "0.3619753114853696",
         "1.0125828852682437",
         "0.1927683442835669",
         "-0.2400601784967314",
         "-0.3223821360076788",
         "-0.0491710980160923",
         "-0.5568794228423727",
         "0.7057999509444245",
         "0.4088773556625631",
         "0.1091651316540571"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5321
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>营业总收入</th>\n",
       "      <th>现金资产比率</th>\n",
       "      <th>应收类资产比率</th>\n",
       "      <th>固定资产比率</th>\n",
       "      <th>无形资产比率</th>\n",
       "      <th>金融负债比率</th>\n",
       "      <th>少数股东权益占比</th>\n",
       "      <th>市盈率（PE）1</th>\n",
       "      <th>资产负债率</th>\n",
       "      <th>市值A</th>\n",
       "      <th>托宾Q值A</th>\n",
       "      <th>账面市值比A</th>\n",
       "      <th>资产报酬率A</th>\n",
       "      <th>净资产收益率（ROE）A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.294663</td>\n",
       "      <td>-0.777553</td>\n",
       "      <td>-1.270996</td>\n",
       "      <td>-1.297656</td>\n",
       "      <td>-0.692415</td>\n",
       "      <td>-1.477725</td>\n",
       "      <td>-0.185208</td>\n",
       "      <td>-0.330143</td>\n",
       "      <td>2.323068</td>\n",
       "      <td>4.379345</td>\n",
       "      <td>-0.733083</td>\n",
       "      <td>1.421790</td>\n",
       "      <td>-0.375351</td>\n",
       "      <td>0.132565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.324778</td>\n",
       "      <td>-0.706152</td>\n",
       "      <td>-1.208915</td>\n",
       "      <td>-1.205924</td>\n",
       "      <td>-0.608636</td>\n",
       "      <td>-0.188667</td>\n",
       "      <td>1.208350</td>\n",
       "      <td>-0.326349</td>\n",
       "      <td>1.446345</td>\n",
       "      <td>0.858528</td>\n",
       "      <td>-0.829444</td>\n",
       "      <td>1.958758</td>\n",
       "      <td>-0.737222</td>\n",
       "      <td>-0.103471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.151864</td>\n",
       "      <td>0.133231</td>\n",
       "      <td>2.573513</td>\n",
       "      <td>-1.277036</td>\n",
       "      <td>-0.136708</td>\n",
       "      <td>-1.085169</td>\n",
       "      <td>-0.257693</td>\n",
       "      <td>-0.370844</td>\n",
       "      <td>0.840408</td>\n",
       "      <td>-0.068671</td>\n",
       "      <td>3.617179</td>\n",
       "      <td>-2.012428</td>\n",
       "      <td>-2.865983</td>\n",
       "      <td>-0.471754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.076711</td>\n",
       "      <td>-0.165453</td>\n",
       "      <td>-1.251412</td>\n",
       "      <td>-1.287878</td>\n",
       "      <td>-0.710005</td>\n",
       "      <td>0.400996</td>\n",
       "      <td>0.012098</td>\n",
       "      <td>-0.370844</td>\n",
       "      <td>1.215474</td>\n",
       "      <td>-0.053009</td>\n",
       "      <td>-0.664129</td>\n",
       "      <td>1.108182</td>\n",
       "      <td>-1.008012</td>\n",
       "      <td>-0.196261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.150626</td>\n",
       "      <td>1.671150</td>\n",
       "      <td>-0.842090</td>\n",
       "      <td>-0.384225</td>\n",
       "      <td>-0.707361</td>\n",
       "      <td>0.594283</td>\n",
       "      <td>0.100501</td>\n",
       "      <td>0.064576</td>\n",
       "      <td>0.780991</td>\n",
       "      <td>-0.068667</td>\n",
       "      <td>4.447951</td>\n",
       "      <td>-2.103008</td>\n",
       "      <td>-0.356346</td>\n",
       "      <td>0.001572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5316</th>\n",
       "      <td>-0.148916</td>\n",
       "      <td>0.255536</td>\n",
       "      <td>0.050418</td>\n",
       "      <td>0.063653</td>\n",
       "      <td>-0.494292</td>\n",
       "      <td>-1.182638</td>\n",
       "      <td>-0.185208</td>\n",
       "      <td>-0.140737</td>\n",
       "      <td>-1.544378</td>\n",
       "      <td>-0.069825</td>\n",
       "      <td>-0.522023</td>\n",
       "      <td>0.592871</td>\n",
       "      <td>0.969871</td>\n",
       "      <td>0.106275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5317</th>\n",
       "      <td>-0.149857</td>\n",
       "      <td>0.215799</td>\n",
       "      <td>3.219931</td>\n",
       "      <td>-0.949145</td>\n",
       "      <td>-0.670456</td>\n",
       "      <td>0.700225</td>\n",
       "      <td>-0.185208</td>\n",
       "      <td>-0.148138</td>\n",
       "      <td>-0.198913</td>\n",
       "      <td>-0.069806</td>\n",
       "      <td>0.143840</td>\n",
       "      <td>-0.678933</td>\n",
       "      <td>1.255378</td>\n",
       "      <td>0.184321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>-0.150593</td>\n",
       "      <td>0.936079</td>\n",
       "      <td>-0.717003</td>\n",
       "      <td>0.952690</td>\n",
       "      <td>0.067164</td>\n",
       "      <td>1.518683</td>\n",
       "      <td>-0.185208</td>\n",
       "      <td>-0.019689</td>\n",
       "      <td>0.223056</td>\n",
       "      <td>-0.069697</td>\n",
       "      <td>-0.208876</td>\n",
       "      <td>-0.160995</td>\n",
       "      <td>0.756657</td>\n",
       "      <td>0.153632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>-0.148657</td>\n",
       "      <td>1.784303</td>\n",
       "      <td>-0.655317</td>\n",
       "      <td>-1.041496</td>\n",
       "      <td>0.039194</td>\n",
       "      <td>-0.601230</td>\n",
       "      <td>-0.185208</td>\n",
       "      <td>-0.230032</td>\n",
       "      <td>0.294809</td>\n",
       "      <td>-0.069054</td>\n",
       "      <td>-0.508312</td>\n",
       "      <td>0.550499</td>\n",
       "      <td>0.700999</td>\n",
       "      <td>0.165490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>-0.134147</td>\n",
       "      <td>-0.518641</td>\n",
       "      <td>3.395994</td>\n",
       "      <td>-0.778235</td>\n",
       "      <td>-0.406620</td>\n",
       "      <td>0.413979</td>\n",
       "      <td>-0.185208</td>\n",
       "      <td>-0.267509</td>\n",
       "      <td>0.628169</td>\n",
       "      <td>-0.069397</td>\n",
       "      <td>-0.594569</td>\n",
       "      <td>0.837051</td>\n",
       "      <td>0.443009</td>\n",
       "      <td>0.133625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5321 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         营业总收入    现金资产比率   应收类资产比率    固定资产比率    无形资产比率    金融负债比率  少数股东权益占比  \\\n",
       "0     1.294663 -0.777553 -1.270996 -1.297656 -0.692415 -1.477725 -0.185208   \n",
       "1     3.324778 -0.706152 -1.208915 -1.205924 -0.608636 -0.188667  1.208350   \n",
       "2    -0.151864  0.133231  2.573513 -1.277036 -0.136708 -1.085169 -0.257693   \n",
       "3    -0.076711 -0.165453 -1.251412 -1.287878 -0.710005  0.400996  0.012098   \n",
       "4    -0.150626  1.671150 -0.842090 -0.384225 -0.707361  0.594283  0.100501   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5316 -0.148916  0.255536  0.050418  0.063653 -0.494292 -1.182638 -0.185208   \n",
       "5317 -0.149857  0.215799  3.219931 -0.949145 -0.670456  0.700225 -0.185208   \n",
       "5318 -0.150593  0.936079 -0.717003  0.952690  0.067164  1.518683 -0.185208   \n",
       "5319 -0.148657  1.784303 -0.655317 -1.041496  0.039194 -0.601230 -0.185208   \n",
       "5320 -0.134147 -0.518641  3.395994 -0.778235 -0.406620  0.413979 -0.185208   \n",
       "\n",
       "      市盈率（PE）1     资产负债率       市值A     托宾Q值A    账面市值比A    资产报酬率A  净资产收益率（ROE）A  \n",
       "0    -0.330143  2.323068  4.379345 -0.733083  1.421790 -0.375351      0.132565  \n",
       "1    -0.326349  1.446345  0.858528 -0.829444  1.958758 -0.737222     -0.103471  \n",
       "2    -0.370844  0.840408 -0.068671  3.617179 -2.012428 -2.865983     -0.471754  \n",
       "3    -0.370844  1.215474 -0.053009 -0.664129  1.108182 -1.008012     -0.196261  \n",
       "4     0.064576  0.780991 -0.068667  4.447951 -2.103008 -0.356346      0.001572  \n",
       "...        ...       ...       ...       ...       ...       ...           ...  \n",
       "5316 -0.140737 -1.544378 -0.069825 -0.522023  0.592871  0.969871      0.106275  \n",
       "5317 -0.148138 -0.198913 -0.069806  0.143840 -0.678933  1.255378      0.184321  \n",
       "5318 -0.019689  0.223056 -0.069697 -0.208876 -0.160995  0.756657      0.153632  \n",
       "5319 -0.230032  0.294809 -0.069054 -0.508312  0.550499  0.700999      0.165490  \n",
       "5320 -0.267509  0.628169 -0.069397 -0.594569  0.837051  0.443009      0.133625  \n",
       "\n",
       "[5321 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data_dir = r\"D:\\Important Files\\Repositories\\Quantitative-Investment-Algorithms\\Data\\Cluster DATA\\processed_data_final.csv\"\n",
    "data_dir = os.path.join(gr.default_dir, r'Data\\Cluster DATA\\processed_data_final.csv')\n",
    "df = gr.read_and_return_pd_df(data_dir)\n",
    "to_drop = ['证券简称', '行业代码1']\n",
    "df.drop(to_drop, axis = 1, inplace = True)\n",
    "df['证券代码'] = df['证券代码'].astype(str).str.zfill(6)\n",
    "Stock_ID_df = df['证券代码']\n",
    "df.drop(['证券代码'], axis = 1, inplace = True)\n",
    "display(Stock_ID_df)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02633a66",
   "metadata": {},
   "source": [
    "## Move data to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a48a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: Cuda.\n"
     ]
    }
   ],
   "source": [
    "device = gr.set_device()\n",
    "print(f\"Current device: {device.capitalize()}.\")\n",
    "X = np.array(df, dtype = np.float64)\n",
    "X_gpu = torch.tensor(X, device = device, dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645967b0",
   "metadata": {},
   "source": [
    "# K is set as 10, which is based on the elbow method, and run wcss for single k function to get the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2f9d51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering with: k = 10.\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "Initiating centroids with k being 10...\n",
      "torch.Size([5321, 14])\n",
      "torch.Size([5321])\n",
      "torch.Size([10, 14])\n",
      "37431.25203033001\n"
     ]
    }
   ],
   "source": [
    "X, y, centroids, var = kmc.WCSS_for_single_k(X = X_gpu, k = 10, n_restarts = 50)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(centroids.shape)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c3cec",
   "metadata": {},
   "source": [
    "# SVC/OVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cccd8c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current training device: Cuda.\n"
     ]
    }
   ],
   "source": [
    "import SVM.SVC as svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fc1384",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c05cccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cpu = 0.01\n",
    "lr = torch.tensor(lr_cpu, device = X.device, dtype = X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9384c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 0 and label b: 1\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.1088631818215493 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.0670159189092645 | Relative Ratio: 1.0392189677498553\n",
      "Epoch 1000 | Loss: 0.004995962393397344 | Relative Ratio: 1.0000023184658555\n",
      "Epoch 2000 | Loss: 0.004979718140941919 | Relative Ratio: 1.0000042524981985\n",
      "Epoch 3000 | Loss: 0.004956536898295101 | Relative Ratio: 1.0000035932291758\n",
      "Epoch 4000 | Loss: 0.0049366645059091335 | Relative Ratio: 1.0000017699376975\n",
      "Epoch 5000 | Loss: 0.004920395971426018 | Relative Ratio: 1.0000059040217\n",
      "Epoch 6000 | Loss: 0.004897733819565722 | Relative Ratio: 1.0000035049351461\n",
      "Epoch 7000 | Loss: 0.0048825029947621185 | Relative Ratio: 1.0000062642358702\n",
      "Epoch 8000 | Loss: 0.004868387904324879 | Relative Ratio: 1.0000024992720278\n",
      "Epoch 9000 | Loss: 0.004848369717873085 | Relative Ratio: 1.0000076886054061\n",
      "Epoch 9999 | Loss: 0.004832610860977807 | Relative Ratio: 1.0000021252485773\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 0 and label b: 2\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.5349452755813164 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.486799020794449 | Relative Ratio: 1.0323824902448087\n",
      "Epoch 1000 | Loss: 9.56487232601102e-05 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 2000 | Loss: 7.609526885864967e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 3000 | Loss: 6.462491472790094e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 4000 | Loss: 5.9481678192644474e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 5000 | Loss: 5.7134084239701246e-05 | Relative Ratio: 1.0006625703437015\n",
      "Epoch 6000 | Loss: 5.4783736047202104e-05 | Relative Ratio: 1.0007683233963276\n",
      "Epoch 7000 | Loss: 5.543088548733724e-05 | Relative Ratio: 1.0001975731506647\n",
      "Epoch 8000 | Loss: 5.550590317894555e-05 | Relative Ratio: 1.000871738038613\n",
      "Epoch 9000 | Loss: 5.303508794179426e-05 | Relative Ratio: 1.0001378267455225\n",
      "Epoch 9999 | Loss: 5.318515689427725e-05 | Relative Ratio: 1.0308308311026593\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 0 and label b: 3\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 0.6705816930132462 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 0.6606895006947567 | Relative Ratio: 1.0149725284087112\n",
      "Epoch 1000 | Loss: 0.006555602467427052 | Relative Ratio: 1.0000029081233894\n",
      "Epoch 1339 | Loss: 0.0065527054714470635 | Relative Ratio: 1.0000005159386922\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 1329 to epoch 1339.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 0 and label b: 4\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 2.3073549407958405 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 2.2677508535291055 | Relative Ratio: 1.0174640380820947\n",
      "Epoch 1000 | Loss: 8.002025312274378e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 2000 | Loss: 8.937008087381292e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 3000 | Loss: 3.802875622349053e-05 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 4000 | Loss: 1.9016490914890955e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 5000 | Loss: 1.1487615085664766e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 6000 | Loss: 7.721370468027316e-06 | Relative Ratio: 1.001000750500313\n",
      "Epoch 7000 | Loss: 4.764503034404323e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 8000 | Loss: 1.7523244317653167e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9000 | Loss: 2.2902412334031338e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9999 | Loss: 1.1791202544992601e-05 | Relative Ratio: 1.0010007505003125\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 0 and label b: 5\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 0.14160815529769083 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 0.1357392274416751 | Relative Ratio: 1.0432367854645224\n",
      "Epoch 1000 | Loss: 0.0001701075861757926 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 2000 | Loss: 6.922237829077506e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 3000 | Loss: 4.3167761693111154e-05 | Relative Ratio: 1.0005459420850145\n",
      "Epoch 4000 | Loss: 1.8939965084148104e-05 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 5000 | Loss: 1.1071705740059899e-05 | Relative Ratio: 1.0010007505003122\n",
      "Epoch 6000 | Loss: 8.04796238191877e-06 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 7000 | Loss: 6.7732206309664564e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 8000 | Loss: 6.883983897928603e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9000 | Loss: 0.0002375849475879136 | Relative Ratio: 1.0010007505003122\n",
      "Epoch 9999 | Loss: 9.653673560060704e-05 | Relative Ratio: 1.001000750500313\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 0 and label b: 6\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 2.512122278189955 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 2.415040458048473 | Relative Ratio: 1.040198838002048\n",
      "Epoch 1000 | Loss: 0.00013135746449633587 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 2000 | Loss: 5.444060146172647e-05 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 3000 | Loss: 3.109990057831694e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 4000 | Loss: 2.2723262480855118e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 5000 | Loss: 2.343569897542537e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 6000 | Loss: 2.1873799618282787e-05 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 7000 | Loss: 2.5411906739778833e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 8000 | Loss: 4.076077887867136e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 9000 | Loss: 2.9560994244100683e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 9999 | Loss: 3.2344487055286965e-05 | Relative Ratio: 1.0010007505003125\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 0 and label b: 7\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 0.829768823393355 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 0.8133098167647985 | Relative Ratio: 1.020237068690536\n",
      "Epoch 1000 | Loss: 0.006561730328846397 | Relative Ratio: 0.9999988119944977\n",
      "Epoch 2000 | Loss: 0.006545828417128323 | Relative Ratio: 1.0000042688807915\n",
      "Epoch 3000 | Loss: 0.0065307936683633985 | Relative Ratio: 1.000005064774167\n",
      "Epoch 4000 | Loss: 0.0065145952602411366 | Relative Ratio: 1.000000959373519\n",
      "Epoch 5000 | Loss: 0.006500350846623078 | Relative Ratio: 1.0000042827093303\n",
      "Epoch 6000 | Loss: 0.006484664211857362 | Relative Ratio: 1.0000028196286008\n",
      "Epoch 7000 | Loss: 0.006468978528715315 | Relative Ratio: 1.0000078655632076\n",
      "Epoch 8000 | Loss: 0.006453438452474934 | Relative Ratio: 1.000004005967584\n",
      "Epoch 9000 | Loss: 0.006439067598294477 | Relative Ratio: 1.0000023984014288\n",
      "Epoch 9999 | Loss: 0.00642386422815247 | Relative Ratio: 1.0000044459738626\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 0 and label b: 8\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 0.6091095549760379 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 0.597871412722095 | Relative Ratio: 1.0187969219046216\n",
      "Epoch 358 | Loss: 0.005747722900088178 | Relative Ratio: 1.0000003311475472\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 348 to epoch 358.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 0 and label b: 9\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.3287964625796391 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.3014123529859405 | Relative Ratio: 1.0210418392993343\n",
      "Epoch 1000 | Loss: 0.007766234583187697 | Relative Ratio: 1.0000099962248743\n",
      "Epoch 2000 | Loss: 0.007738845651894284 | Relative Ratio: 1.0000015079993252\n",
      "Epoch 3000 | Loss: 0.007713143728970031 | Relative Ratio: 1.0000052750816046\n",
      "Epoch 4000 | Loss: 0.007687345756223951 | Relative Ratio: 1.0000143651088838\n",
      "Epoch 5000 | Loss: 0.007660252254120418 | Relative Ratio: 1.0000038815285428\n",
      "Epoch 6000 | Loss: 0.007633801170936845 | Relative Ratio: 1.000005892842385\n",
      "Epoch 7000 | Loss: 0.007605137250263598 | Relative Ratio: 1.000004091806717\n",
      "Epoch 8000 | Loss: 0.007578108233686868 | Relative Ratio: 1.0000117454113917\n",
      "Epoch 9000 | Loss: 0.007553321275522121 | Relative Ratio: 0.9999959105909082\n",
      "Epoch 9999 | Loss: 0.0075089142667683515 | Relative Ratio: 1.000002436759159\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 1 and label b: 2\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.2927983143057444 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.2685267020126942 | Relative Ratio: 1.0191337023135105\n",
      "Epoch 964 | Loss: 0.009675209743622551 | Relative Ratio: 0.999999181898381\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 954 to epoch 964.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 1 and label b: 3\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 0.6636646068356294 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 0.6596827419869448 | Relative Ratio: 1.0060360300417917\n",
      "Epoch 1000 | Loss: 0.01989533115080036 | Relative Ratio: 1.0000048605505083\n",
      "Epoch 1054 | Loss: 0.019893962021986643 | Relative Ratio: 0.9999995964026515\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 1044 to epoch 1054.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 1 and label b: 4\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.6720010633213458 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.6159493252505934 | Relative Ratio: 1.0346865691856149\n",
      "Epoch 1000 | Loss: 8.091977276953615e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 2000 | Loss: 3.941449049396788e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 3000 | Loss: 1.5119981584904559e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 4000 | Loss: 7.4320224796086e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 5000 | Loss: 5.315069479904389e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 6000 | Loss: 2.8418500951884477e-06 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 7000 | Loss: 5.117566154279568e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 8000 | Loss: 1.0422169432207833e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 9000 | Loss: 4.6134021238336896e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9999 | Loss: 4.5434076253135305e-06 | Relative Ratio: 1.0010007505003127\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 1 and label b: 5\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.7826311205148393 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.7044780929221506 | Relative Ratio: 1.0458515881883255\n",
      "Epoch 1000 | Loss: 8.340233712316185e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 2000 | Loss: 3.154681405552773e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 3000 | Loss: 1.2791482165227687e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 4000 | Loss: 5.146589563542628e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 5000 | Loss: 4.043126333650799e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 6000 | Loss: 1.4870111329577088e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 7000 | Loss: 5.4690403590320865e-06 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 8000 | Loss: 2.0114444193318897e-06 | Relative Ratio: 1.001000750500313\n",
      "Epoch 9000 | Loss: 2.7525887130420758e-05 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 9999 | Loss: 1.013380716947268e-05 | Relative Ratio: 1.0010007505003127\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 1 and label b: 6\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.288931064980741 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.2567299754125203 | Relative Ratio: 1.0256229183660959\n",
      "Epoch 1000 | Loss: 0.014444659179290428 | Relative Ratio: 1.0000011218421523\n",
      "Epoch 2000 | Loss: 0.01398960270511976 | Relative Ratio: 1.0000082199320108\n",
      "Epoch 3000 | Loss: 0.01394852645019326 | Relative Ratio: 1.0000023431832297\n",
      "Epoch 3251 | Loss: 0.013943175491833576 | Relative Ratio: 1.0000008880395201\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 3241 to epoch 3251.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 1 and label b: 7\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.7626606730597734 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.7463826453484435 | Relative Ratio: 1.0093209971793335\n",
      "Epoch 1000 | Loss: 0.012098796803698264 | Relative Ratio: 1.0000021928712133\n",
      "Epoch 2000 | Loss: 0.012032739170446827 | Relative Ratio: 1.0000022119632832\n",
      "Epoch 3000 | Loss: 0.01200764282740617 | Relative Ratio: 1.000000049660166\n",
      "Epoch 3833 | Loss: 0.011992616884431914 | Relative Ratio: 1.0000006663687644\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 3823 to epoch 3833.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 1 and label b: 8\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.4156404259360222 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.381203327061418 | Relative Ratio: 1.024932678773567\n",
      "Epoch 967 | Loss: 0.0026476994779035187 | Relative Ratio: 0.9999996756616898\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 957 to epoch 967.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 1 and label b: 9\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 2.4139740753778614 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 2.3808731370340475 | Relative Ratio: 1.013902856825479\n",
      "Epoch 571 | Loss: 0.00795963249395876 | Relative Ratio: 1.0000000060211778\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 561 to epoch 571.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 2 and label b: 3\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 0.8339052173764199 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 0.8301156649582704 | Relative Ratio: 1.0045650896352378\n",
      "Epoch 1000 | Loss: 0.028343289624577928 | Relative Ratio: 1.0010991484231662\n",
      "Epoch 2000 | Loss: 0.025838838590388564 | Relative Ratio: 1.000549512198488\n",
      "Epoch 3000 | Loss: 0.024997002897110827 | Relative Ratio: 1.000003147359263\n",
      "Epoch 3261 | Loss: 0.024990820631805438 | Relative Ratio: 1.000000339834459\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 3251 to epoch 3261.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 2 and label b: 4\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.4063974871660514 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.3605420372335013 | Relative Ratio: 1.0337038097152746\n",
      "Epoch 1000 | Loss: 9.71840992340102e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 2000 | Loss: 3.8828815358123136e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 3000 | Loss: 1.6522781370751446e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 4000 | Loss: 8.599759991769903e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 5000 | Loss: 3.4304901620273144e-06 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 6000 | Loss: 8.167368458559917e-06 | Relative Ratio: 1.001000750500313\n",
      "Epoch 7000 | Loss: 5.015652022741828e-06 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 8000 | Loss: 3.870010708857032e-06 | Relative Ratio: 1.001000750500313\n",
      "Epoch 9000 | Loss: 2.358807167368164e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9999 | Loss: 1.8992749107828416e-06 | Relative Ratio: 1.0010007505003131\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 2 and label b: 5\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.0355255448983285 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 0.9839490791800812 | Relative Ratio: 1.0524178199965648\n",
      "Epoch 1000 | Loss: 7.694563305157017e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 2000 | Loss: 3.0602520648394836e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 3000 | Loss: 1.2730744205859874e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 4000 | Loss: 2.0707511615967527e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 5000 | Loss: 8.219451623847015e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 6000 | Loss: 3.565789066579023e-06 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 7000 | Loss: 1.6328764390388122e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 8000 | Loss: 8.484355428927522e-07 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9000 | Loss: 1.0407646872288464e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 9999 | Loss: 3.831632600686504e-06 | Relative Ratio: 1.0010007505003122\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 2 and label b: 6\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 2.6939569794995117 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 2.6320652049398805 | Relative Ratio: 1.023514529367841\n",
      "Epoch 1000 | Loss: 0.00248086948063781 | Relative Ratio: 1.0000280881869175\n",
      "Epoch 1577 | Loss: 0.0024690227185780733 | Relative Ratio: 1.0000008738010686\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 1567 to epoch 1577.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 2 and label b: 7\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.1152571031556762 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.09801859884077 | Relative Ratio: 1.015699646921378\n",
      "Epoch 1000 | Loss: 0.00838926831947318 | Relative Ratio: 1.0001075041013803\n",
      "Epoch 1942 | Loss: 0.00800903845358467 | Relative Ratio: 1.0000001079015457\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 1932 to epoch 1942.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 2 and label b: 8\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.086192762603193 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.0728171282166303 | Relative Ratio: 1.012467767371311\n",
      "Epoch 800 | Loss: 0.007974159275427287 | Relative Ratio: 1.0000006267045352\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 790 to epoch 800.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 2 and label b: 9\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 2.333394594086863 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 2.300535273723269 | Relative Ratio: 1.0142833368994222\n",
      "Epoch 1000 | Loss: 0.004048024246620568 | Relative Ratio: 1.0000036890891268\n",
      "Epoch 2000 | Loss: 0.004038171916962377 | Relative Ratio: 1.0000074536774293\n",
      "Epoch 3000 | Loss: 0.004029824411025454 | Relative Ratio: 1.0000018455503163\n",
      "Epoch 4000 | Loss: 0.004019472484606885 | Relative Ratio: 1.0000027281175659\n",
      "Epoch 5000 | Loss: 0.004007686047869297 | Relative Ratio: 1.000002736619708\n",
      "Epoch 5186 | Loss: 0.004006633713897268 | Relative Ratio: 1.0000006774216794\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 5176 to epoch 5186.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 3 and label b: 4\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 2.140455954698872 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 2.1224089240692696 | Relative Ratio: 1.008503088365743\n",
      "Epoch 1000 | Loss: 4.153259877829168e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 2000 | Loss: 1.716145711610035e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 3000 | Loss: 7.955623411970242e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 4000 | Loss: 4.4975814959977305e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 5000 | Loss: 3.22166629601697e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 6000 | Loss: 2.7762313024578065e-06 | Relative Ratio: 1.001000750500313\n",
      "Epoch 7000 | Loss: 2.6274172161693073e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 8000 | Loss: 2.3681988272467997e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9000 | Loss: 2.290158820650581e-06 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 9999 | Loss: 2.1943924711572555e-06 | Relative Ratio: 1.0010007505003127\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 3 and label b: 5\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.3815263287829813 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.3652243745807588 | Relative Ratio: 1.01194086078871\n",
      "Epoch 1000 | Loss: 5.381207485438058e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 2000 | Loss: 1.9791405905380895e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 3000 | Loss: 7.27903075232674e-06 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 4000 | Loss: 6.554313646033824e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 5000 | Loss: 2.4105943164403428e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 6000 | Loss: 8.865863418011516e-07 | Relative Ratio: 1.001000750500313\n",
      "Epoch 7000 | Loss: 3.260753317584623e-07 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 8000 | Loss: 1.704857953134133e-06 | Relative Ratio: 1.0010007505003122\n",
      "Epoch 9000 | Loss: 6.270253628540004e-07 | Relative Ratio: 1.001000750500313\n",
      "Epoch 9999 | Loss: 2.3084284577003516e-07 | Relative Ratio: 1.0010007505003127\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 3 and label b: 6\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 2.272726352227879 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 2.252940625462537 | Relative Ratio: 1.008782178518921\n",
      "Epoch 556 | Loss: 0.0012710971951972892 | Relative Ratio: 1.0000009715063083\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 546 to epoch 556.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 3 and label b: 7\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.8464509058535392 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.8363166119049699 | Relative Ratio: 1.0055188162449047\n",
      "Epoch 1000 | Loss: 0.022394282124697018 | Relative Ratio: 1.0000023190400416\n",
      "Epoch 2000 | Loss: 0.02231962341630112 | Relative Ratio: 1.000012169290324\n",
      "Epoch 3000 | Loss: 0.02215048142699882 | Relative Ratio: 1.000003421791814\n",
      "Epoch 4000 | Loss: 0.021994480459279448 | Relative Ratio: 1.0000055286171063\n",
      "Epoch 4665 | Loss: 0.021968432600783374 | Relative Ratio: 1.0000005360118451\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 4655 to epoch 4665.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 3 and label b: 8\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.6839419955954256 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.6732111735791537 | Relative Ratio: 1.0064133100386352\n",
      "Epoch 891 | Loss: 0.01636252620025842 | Relative Ratio: 0.9999998353104244\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 881 to epoch 891.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 3 and label b: 9\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.7669160648267939 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.753285837348124 | Relative Ratio: 1.0077741045916881\n",
      "Epoch 889 | Loss: 0.020117703111014955 | Relative Ratio: 1.0000008978037982\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 879 to epoch 889.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 4 and label b: 5\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 0.00023531783300010547 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 0.00023531736236467478 | Relative Ratio: 1.000002000003\n",
      "Epoch 1000 | Loss: 9.646059557317091e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 2000 | Loss: 3.547699667833943e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 3000 | Loss: 0.001403469028335535 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 4000 | Loss: 0.0005161782980973073 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 5000 | Loss: 0.00018984390111025196 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 6000 | Loss: 6.982220469479143e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 7000 | Loss: 0.025163357631320774 | Relative Ratio: 1.0004951667165696\n",
      "Epoch 8000 | Loss: 0.009290146575173516 | Relative Ratio: 1.001000750500313\n",
      "Epoch 9000 | Loss: 0.0034167993389456917 | Relative Ratio: 1.0010007505003122\n",
      "Epoch 9999 | Loss: 0.001257913522408899 | Relative Ratio: 1.0010007505003127\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 4 and label b: 6\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 3.7595999946916288 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 3.0703220658559656 | Relative Ratio: 1.224496946591009\n",
      "Epoch 1000 | Loss: 8.403568945294087e-05 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 2000 | Loss: 3.0907272113227093e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 3000 | Loss: 6.817104381242912e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 4000 | Loss: 2.5072454513904764e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 5000 | Loss: 9.221334164714771e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 6000 | Loss: 0.0001326243595145848 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 7000 | Loss: 0.00011398483579848294 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 8000 | Loss: 4.192219234160095e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9000 | Loss: 1.541845630969072e-05 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 9999 | Loss: 5.676389732800491e-06 | Relative Ratio: 1.001000750500313\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 4 and label b: 7\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.1988808418040442 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.1750679143826652 | Relative Ratio: 1.0202651498946675\n",
      "Epoch 1000 | Loss: 9.408575661977774e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 2000 | Loss: 3.460356071041398e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 3000 | Loss: 1.3452762657928788e-05 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 4000 | Loss: 6.463638131289608e-06 | Relative Ratio: 1.001000750500313\n",
      "Epoch 5000 | Loss: 4.696641231437707e-06 | Relative Ratio: 1.001000750500313\n",
      "Epoch 6000 | Loss: 4.108726187438335e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 7000 | Loss: 3.0275849118296235e-06 | Relative Ratio: 1.001000750500313\n",
      "Epoch 8000 | Loss: 2.329229081207647e-06 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 9000 | Loss: 2.6012806218719665e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9999 | Loss: 3.2374557458833527e-06 | Relative Ratio: 1.0010007505003127\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 4 and label b: 8\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.7629966283170175 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.7247033313705369 | Relative Ratio: 1.0222028312057883\n",
      "Epoch 171 | Loss: 0.008810647793727065 | Relative Ratio: 0.9999998968565108\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 161 to epoch 171.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 4 and label b: 9\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 2.1256574018274446 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 2.087431452549715 | Relative Ratio: 1.018312433316571\n",
      "Epoch 1000 | Loss: 9.610597900899226e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 2000 | Loss: 3.53465731557113e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 3000 | Loss: 1.3917788802726847e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 4000 | Loss: 6.846644352070314e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 5000 | Loss: 4.0697965604985405e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 6000 | Loss: 3.904988556763038e-06 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 7000 | Loss: 2.5396359767718895e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 8000 | Loss: 3.1585126247986068e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9000 | Loss: 2.198048711054137e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9999 | Loss: 2.9538342781661134e-06 | Relative Ratio: 1.0010007505003127\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 5 and label b: 6\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 8.191947910568212 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 7.081545678285952 | Relative Ratio: 1.156802241025864\n",
      "Epoch 1000 | Loss: 0.0001762270325082937 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 2000 | Loss: 6.481409128547043e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 3000 | Loss: 2.383780949703952e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 4000 | Loss: 8.767247219657146e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 5000 | Loss: 0.0022870249561725907 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 6000 | Loss: 0.0008411390816249644 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 7000 | Loss: 0.00030936039973124626 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 8000 | Loss: 0.00011377887321201366 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9000 | Loss: 7.55638163638943e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9999 | Loss: 2.78192357758696e-05 | Relative Ratio: 1.0010007505003127\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 5 and label b: 7\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 0.9248613940699167 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 0.908116821735539 | Relative Ratio: 1.0184387866556381\n",
      "Epoch 1000 | Loss: 0.0001002561302785056 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 2000 | Loss: 3.9355231818979335e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 3000 | Loss: 1.447436043931643e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 4000 | Loss: 5.323488147418625e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 5000 | Loss: 4.50819218354024e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 6000 | Loss: 1.658056516968643e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 7000 | Loss: 6.098123818899194e-07 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 8000 | Loss: 1.5723351640848139e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9000 | Loss: 5.782851439182688e-07 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 9999 | Loss: 1.8564147620175763e-06 | Relative Ratio: 1.0010007505003127\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 5 and label b: 8\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.1988120697691078 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.173635744245459 | Relative Ratio: 1.0214515667634465\n",
      "Epoch 1000 | Loss: 0.00010788997648142054 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 2000 | Loss: 4.580741238028067e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 3000 | Loss: 1.6847391488743204e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 4000 | Loss: 6.196259190950574e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 5000 | Loss: 2.278906380675765e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 6000 | Loss: 5.210887573929919e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 7000 | Loss: 1.9164990642347845e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 8000 | Loss: 7.048643078750483e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9000 | Loss: 1.3577035310715917e-05 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 9999 | Loss: 4.9984604354444156e-06 | Relative Ratio: 1.0010007505003127\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 5 and label b: 9\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.7426387346076955 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.7021913231707906 | Relative Ratio: 1.0237619654655274\n",
      "Epoch 1000 | Loss: 8.103863598932173e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 2000 | Loss: 2.9804993455897355e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 3000 | Loss: 1.0961902604371804e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 4000 | Loss: 4.031650229534189e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 5000 | Loss: 2.2062478036527664e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 6000 | Loss: 8.114302585080945e-07 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 7000 | Loss: 1.0748146387570084e-06 | Relative Ratio: 1.001000750500313\n",
      "Epoch 8000 | Loss: 4.607076870263497e-06 | Relative Ratio: 1.0010007505003125\n",
      "Epoch 9000 | Loss: 1.694425063954842e-06 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9999 | Loss: 6.238119331043442e-07 | Relative Ratio: 1.0010007505003127\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 6 and label b: 7\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.4569161834384698 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.4290559748552671 | Relative Ratio: 1.019495533466437\n",
      "Epoch 299 | Loss: 0.0002688064727756262 | Relative Ratio: 0.999999513548642\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 289 to epoch 299.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 6 and label b: 8\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 0.665091048939904 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 0.6460382073519845 | Relative Ratio: 1.029491818550507\n",
      "Epoch 1000 | Loss: 9.88380866209559e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 2000 | Loss: 4.5746088695385616e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 3000 | Loss: 3.677428574045392e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 4000 | Loss: 3.3624510767887216e-05 | Relative Ratio: 1.0003351081097271\n",
      "Epoch 5000 | Loss: 2.9700288850435904e-05 | Relative Ratio: 1.0002116807844448\n",
      "Epoch 6000 | Loss: 2.6749591559963867e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 7000 | Loss: 2.6264314661732225e-05 | Relative Ratio: 1.0007683233963276\n",
      "Epoch 8000 | Loss: 2.44429635073921e-05 | Relative Ratio: 1.0010007505003127\n",
      "Epoch 9000 | Loss: 2.320767297975418e-05 | Relative Ratio: 1.001000750500313\n",
      "Epoch 9999 | Loss: 2.3821234971426845e-05 | Relative Ratio: 1.0003039458322565\n",
      "Max epoch reached. \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 6 and label b: 9\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.8405752045889818 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.8008286211050082 | Relative Ratio: 1.0220712748665581\n",
      "Epoch 430 | Loss: 0.0015124227718659382 | Relative Ratio: 1.0000008723341705\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 420 to epoch 430.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 7 and label b: 8\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.4603455796797304 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.4461113294563845 | Relative Ratio: 1.0098431219875006\n",
      "Epoch 1000 | Loss: 0.014864855387424832 | Relative Ratio: 0.9999990655171167\n",
      "Epoch 1053 | Loss: 0.0148644280238567 | Relative Ratio: 0.9999997110391078\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 1043 to epoch 1053.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 7 and label b: 9\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.5583435051108747 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.5395577983098818 | Relative Ratio: 1.012202014644475\n",
      "Epoch 865 | Loss: 0.017845738962097124 | Relative Ratio: 1.0000007118725094\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 855 to epoch 865.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training on label a: 8 and label b: 9\n",
      "Creating random weights and bias with dtype: torch.float64\n",
      "Training with loss function: hinge loss with l2 penalty on weights.\n",
      "Training with relative breaker.\n",
      "Epoch 0 | Loss: 1.4922092631344772 | Relative Ratio: None\n",
      "Epoch 1 | Loss: 1.476242225965251 | Relative Ratio: 1.0108160008489027\n",
      "Epoch 1000 | Loss: 0.02190612438476308 | Relative Ratio: 1.000000655041789\n",
      "Epoch 1554 | Loss: 0.021896603652143517 | Relative Ratio: 1.0000004273683247\n",
      "Exited with relative_ratio consecutively being smaller than 1e-06 from epoch 1544 to epoch 1554.\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "wb_dic = svc.ovo_train(\n",
    "    X,\n",
    "    y,\n",
    "    num_epochs = int(1e4),\n",
    "    start_learning_rate = lr,\n",
    "    l2_penalty = True,\n",
    "    print_every = int(1e3),\n",
    "    delta_loss_breaker = 1e-7,\n",
    "    patience = int(10),\n",
    "    relative = True,\n",
    "    relative_breaker = 1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "babb7086",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = svc.ovo_predict(wb_dic, X, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e033af05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 5252/5321 = 98.70%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9870325126855855"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.ovo_score(X, y, wb_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b0e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2947, -0.7776, -1.2710,  ...,  1.4218, -0.3754,  0.1326],\n",
      "        [ 3.3248, -0.7062, -1.2089,  ...,  1.9588, -0.7372, -0.1035],\n",
      "        [-0.1519,  0.1332,  2.5735,  ..., -2.0124, -2.8660, -0.4718],\n",
      "        ...,\n",
      "        [-0.1506,  0.9361, -0.7170,  ..., -0.1610,  0.7567,  0.1536],\n",
      "        [-0.1487,  1.7843, -0.6553,  ...,  0.5505,  0.7010,  0.1655],\n",
      "        [-0.1341, -0.5186,  3.3960,  ...,  0.8371,  0.4430,  0.1336]],\n",
      "       device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f15a3c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3b345d7e-16ea-4523-95e8-f1acefafcde0",
       "rows": [
        [
         "0",
         "8"
        ],
        [
         "1",
         "8"
        ],
        [
         "2",
         "1"
        ],
        [
         "3",
         "8"
        ],
        [
         "4",
         "1"
        ],
        [
         "5",
         "7"
        ],
        [
         "6",
         "9"
        ],
        [
         "7",
         "7"
        ],
        [
         "8",
         "8"
        ],
        [
         "9",
         "9"
        ],
        [
         "10",
         "3"
        ],
        [
         "11",
         "8"
        ],
        [
         "12",
         "1"
        ],
        [
         "13",
         "9"
        ],
        [
         "14",
         "1"
        ],
        [
         "15",
         "9"
        ],
        [
         "16",
         "3"
        ],
        [
         "17",
         "3"
        ],
        [
         "18",
         "9"
        ],
        [
         "19",
         "7"
        ],
        [
         "20",
         "3"
        ],
        [
         "21",
         "8"
        ],
        [
         "22",
         "8"
        ],
        [
         "23",
         "8"
        ],
        [
         "24",
         "8"
        ],
        [
         "25",
         "0"
        ],
        [
         "26",
         "8"
        ],
        [
         "27",
         "9"
        ],
        [
         "28",
         "8"
        ],
        [
         "29",
         "8"
        ],
        [
         "30",
         "8"
        ],
        [
         "31",
         "9"
        ],
        [
         "32",
         "9"
        ],
        [
         "33",
         "7"
        ],
        [
         "34",
         "9"
        ],
        [
         "35",
         "8"
        ],
        [
         "36",
         "8"
        ],
        [
         "37",
         "3"
        ],
        [
         "38",
         "9"
        ],
        [
         "39",
         "9"
        ],
        [
         "40",
         "8"
        ],
        [
         "41",
         "7"
        ],
        [
         "42",
         "8"
        ],
        [
         "43",
         "8"
        ],
        [
         "44",
         "7"
        ],
        [
         "45",
         "8"
        ],
        [
         "46",
         "8"
        ],
        [
         "47",
         "7"
        ],
        [
         "48",
         "7"
        ],
        [
         "49",
         "9"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5321
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5316</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5317</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5321 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     8\n",
       "1     8\n",
       "2     1\n",
       "3     8\n",
       "4     1\n",
       "...  ..\n",
       "5316  3\n",
       "5317  7\n",
       "5318  9\n",
       "5319  2\n",
       "5320  7\n",
       "\n",
       "[5321 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "votes_df = gr.detach_to_pd(votes)\n",
    "display(votes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2d2ee1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "证券代码",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f3a6fa0a-8841-45e2-b842-304beb04a95c",
       "rows": [
        [
         "0",
         "000001",
         "8"
        ],
        [
         "1",
         "000002",
         "8"
        ],
        [
         "2",
         "000004",
         "1"
        ],
        [
         "3",
         "000006",
         "8"
        ],
        [
         "4",
         "000007",
         "1"
        ],
        [
         "5",
         "000008",
         "7"
        ],
        [
         "6",
         "000009",
         "9"
        ],
        [
         "7",
         "000010",
         "7"
        ],
        [
         "8",
         "000011",
         "8"
        ],
        [
         "9",
         "000012",
         "9"
        ],
        [
         "10",
         "000014",
         "3"
        ],
        [
         "11",
         "000016",
         "8"
        ],
        [
         "12",
         "000017",
         "1"
        ],
        [
         "13",
         "000019",
         "9"
        ],
        [
         "14",
         "000020",
         "1"
        ],
        [
         "15",
         "000021",
         "9"
        ],
        [
         "16",
         "000025",
         "3"
        ],
        [
         "17",
         "000026",
         "3"
        ],
        [
         "18",
         "000027",
         "9"
        ],
        [
         "19",
         "000028",
         "7"
        ],
        [
         "20",
         "000029",
         "3"
        ],
        [
         "21",
         "000030",
         "8"
        ],
        [
         "22",
         "000031",
         "8"
        ],
        [
         "23",
         "000032",
         "8"
        ],
        [
         "24",
         "000034",
         "8"
        ],
        [
         "25",
         "000035",
         "0"
        ],
        [
         "26",
         "000036",
         "8"
        ],
        [
         "27",
         "000037",
         "9"
        ],
        [
         "28",
         "000039",
         "8"
        ],
        [
         "29",
         "000040",
         "8"
        ],
        [
         "30",
         "000042",
         "8"
        ],
        [
         "31",
         "000045",
         "9"
        ],
        [
         "32",
         "000048",
         "9"
        ],
        [
         "33",
         "000049",
         "7"
        ],
        [
         "34",
         "000050",
         "9"
        ],
        [
         "35",
         "000055",
         "8"
        ],
        [
         "36",
         "000056",
         "8"
        ],
        [
         "37",
         "000058",
         "3"
        ],
        [
         "38",
         "000059",
         "9"
        ],
        [
         "39",
         "000060",
         "9"
        ],
        [
         "40",
         "000061",
         "8"
        ],
        [
         "41",
         "000062",
         "7"
        ],
        [
         "42",
         "000063",
         "8"
        ],
        [
         "43",
         "000065",
         "8"
        ],
        [
         "44",
         "000066",
         "7"
        ],
        [
         "45",
         "000068",
         "8"
        ],
        [
         "46",
         "000069",
         "8"
        ],
        [
         "47",
         "000070",
         "7"
        ],
        [
         "48",
         "000078",
         "7"
        ],
        [
         "49",
         "000088",
         "9"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5321
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>证券代码</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000006</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5316</th>\n",
       "      <td>920002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5317</th>\n",
       "      <td>920008</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>920016</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>920099</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>920118</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5321 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        证券代码  0\n",
       "0     000001  8\n",
       "1     000002  8\n",
       "2     000004  1\n",
       "3     000006  8\n",
       "4     000007  1\n",
       "...      ... ..\n",
       "5316  920002  3\n",
       "5317  920008  7\n",
       "5318  920016  9\n",
       "5319  920099  2\n",
       "5320  920118  7\n",
       "\n",
       "[5321 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.concat([Stock_ID_df, votes_df], axis = 1)\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
