{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9ae08935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import global_resources as gr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "57050465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The input file path is: \n",
      "d:\\Important Files\\Repositories\\Quantitative-Investment-Algorithms\\Data\\breast-cancer-wisconsin.data\n",
      "Reading the input file...\n"
     ]
    }
   ],
   "source": [
    "# Example Data process\n",
    "# Read data\n",
    "data_path = os.path.join(gr.default_dir, r'Data\\breast-cancer-wisconsin.data')\n",
    "df = gr.read_and_return_pd_df(data_path)\n",
    "\n",
    "\n",
    "df.replace('?', np.nan, inplace = True)\n",
    "df.dropna(inplace = True)\n",
    "# df.replace('?', -99999, inplace = True)\n",
    "df.drop(['id'], axis = 1, inplace = True)\n",
    "df[\"bare_nuclei\"] = df[\"bare_nuclei\"].astype(np.int64)\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d860c68",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b9a96b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: Cuda.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Current device: {device.capitalize()}.\")\n",
    "\n",
    "\n",
    "X = np.array(df.drop(['class'], axis = 1)).astype('float64')\n",
    "y = np.array(df['class']).astype('float64')\n",
    "\n",
    "y = np.where(y == 4, 1, np.where(y == 2, -1, y))\n",
    "\n",
    "X_gpu = torch.tensor(X, device = device)\n",
    "y_gpu = torch.tensor(y, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "74903d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_tensor_row_wise(ts = X_gpu):\n",
    "    indices = torch.randperm(ts.shape[0])\n",
    "    ts = ts[indices]\n",
    "\n",
    "shuffle_tensor_row_wise(X_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7386f2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6523, 0.1372, 0.8973, 0.9162, 0.2612, 0.1198, 0.2556, 0.3937, 0.8526,\n",
      "        0.0000], device='cuda:0', dtype=torch.float64)\n",
      "torch.Size([10])\n",
      "tensor(0., device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def create_random_weights_bias(shape = X_gpu.shape[-1] + 1):\n",
    "    weights_bias = torch.rand(1, shape, dtype = torch.float64, device = device)\n",
    "    weights_bias = torch.squeeze(weights_bias)\n",
    "    weights_bias[-1] = 0\n",
    "    return weights_bias\n",
    "\n",
    "weights_bias = create_random_weights_bias()\n",
    "print(weights_bias)\n",
    "print(weights_bias.shape)\n",
    "print(weights_bias[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "67aef3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6523, 0.1372, 0.8973, 0.9162, 0.2612, 0.1198, 0.2556, 0.3937, 0.8526],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "tensor(0., device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# print(weights_bias.T)\n",
    "# random_tensor = torch.rand(9, device = device, dtype = torch.float64)\n",
    "# print(random_tensor)\n",
    "# outcome = torch.matmul(weights_bias, random_tensor)\n",
    "# print(outcome)\n",
    "print(weights_bias[:-1])\n",
    "print(weights_bias[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6689a17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([683])\n",
      "torch.Size([683])\n"
     ]
    }
   ],
   "source": [
    "def cal_signed_distance(n_point, hyperplain_weights = weights_bias[:-1], hyperplain_bias = weights_bias[-1].item()):\n",
    "    raw_scores = torch.matmul(n_point, hyperplain_weights) + hyperplain_bias\n",
    "    \n",
    "    weight_norm = torch.norm(hyperplain_weights)\n",
    "    distances = raw_scores / weight_norm\n",
    "    \n",
    "    return distances\n",
    "\n",
    "distances = cal_signed_distance(X_gpu, hyperplain_weights = weights_bias[:-1] + 1, hyperplain_bias = weights_bias[-1])\n",
    "print(distances.shape)\n",
    "print(y_gpu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d3835091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7871, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def hinge_loss(distances = distances, labels = y_gpu, margin=1.0):\n",
    "    distances = distances.squeeze()\n",
    "    \n",
    "    losses = torch.clamp(margin - labels * distances, min = 0)\n",
    "    \n",
    "    return losses.mean()\n",
    "\n",
    "loss = hinge_loss(distances, y_gpu)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1df2d15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([683])\n"
     ]
    }
   ],
   "source": [
    "print(y_gpu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "16ac2017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model(X = X_gpu, y = y_gpu, weights = weights_bias[:-1], bias = weights_bias[-1], learning_rate = 0.01):\n",
    "    \n",
    "    weights.requires_grad_(True)\n",
    "    bias.requires_grad_(True)\n",
    "    \n",
    "    distances = cal_signed_distance(X, weights, bias)\n",
    "    \n",
    "    loss = hinge_loss(distances, y)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        weights -= learning_rate * weights.grad\n",
    "        bias -= learning_rate * bias.grad\n",
    "    \n",
    "    weights.grad.zero_()\n",
    "    bias.grad.zero_()\n",
    "    \n",
    "    return loss.item(), weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b6842e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss: 0.0704\n",
      "Epoch 002 | Loss: 0.0704\n",
      "Epoch 003 | Loss: 0.0704\n",
      "Epoch 004 | Loss: 0.0704\n",
      "Epoch 005 | Loss: 0.0704\n",
      "Epoch 006 | Loss: 0.0704\n",
      "Epoch 007 | Loss: 0.0705\n",
      "Epoch 008 | Loss: 0.0704\n",
      "Epoch 009 | Loss: 0.0703\n",
      "Epoch 010 | Loss: 0.0704\n",
      "Epoch 011 | Loss: 0.0705\n",
      "Epoch 012 | Loss: 0.0708\n",
      "Epoch 013 | Loss: 0.0713\n",
      "Epoch 014 | Loss: 0.0712\n",
      "Epoch 015 | Loss: 0.0711\n",
      "Epoch 016 | Loss: 0.0706\n",
      "Epoch 017 | Loss: 0.0705\n",
      "Epoch 018 | Loss: 0.0704\n",
      "Epoch 019 | Loss: 0.0704\n",
      "Epoch 020 | Loss: 0.0703\n",
      "Epoch 021 | Loss: 0.0703\n",
      "Epoch 022 | Loss: 0.0705\n",
      "Epoch 023 | Loss: 0.0714\n",
      "Epoch 024 | Loss: 0.0711\n",
      "Epoch 025 | Loss: 0.0712\n",
      "Epoch 026 | Loss: 0.0708\n",
      "Epoch 027 | Loss: 0.0707\n",
      "Epoch 028 | Loss: 0.0704\n",
      "Epoch 029 | Loss: 0.0704\n",
      "Epoch 030 | Loss: 0.0704\n",
      "Epoch 031 | Loss: 0.0704\n",
      "Epoch 032 | Loss: 0.0704\n",
      "Epoch 033 | Loss: 0.0704\n",
      "Epoch 034 | Loss: 0.0703\n",
      "Epoch 035 | Loss: 0.0704\n",
      "Epoch 036 | Loss: 0.0715\n",
      "Epoch 037 | Loss: 0.0711\n",
      "Epoch 038 | Loss: 0.0712\n",
      "Epoch 039 | Loss: 0.0706\n",
      "Epoch 040 | Loss: 0.0704\n",
      "Epoch 041 | Loss: 0.0704\n",
      "Epoch 042 | Loss: 0.0703\n",
      "Epoch 043 | Loss: 0.0704\n",
      "Epoch 044 | Loss: 0.0704\n",
      "Epoch 045 | Loss: 0.0705\n",
      "Epoch 046 | Loss: 0.0704\n",
      "Epoch 047 | Loss: 0.0703\n",
      "Epoch 048 | Loss: 0.0707\n",
      "Epoch 049 | Loss: 0.0711\n",
      "Epoch 050 | Loss: 0.0710\n",
      "Epoch 051 | Loss: 0.0713\n",
      "Epoch 052 | Loss: 0.0710\n",
      "Epoch 053 | Loss: 0.0711\n",
      "Epoch 054 | Loss: 0.0706\n",
      "Epoch 055 | Loss: 0.0705\n",
      "Epoch 056 | Loss: 0.0704\n",
      "Epoch 057 | Loss: 0.0704\n",
      "Epoch 058 | Loss: 0.0704\n",
      "Epoch 059 | Loss: 0.0704\n",
      "Epoch 060 | Loss: 0.0703\n",
      "Epoch 061 | Loss: 0.0703\n",
      "Epoch 062 | Loss: 0.0707\n",
      "Epoch 063 | Loss: 0.0711\n",
      "Epoch 064 | Loss: 0.0714\n",
      "Epoch 065 | Loss: 0.0714\n",
      "Epoch 066 | Loss: 0.0709\n",
      "Epoch 067 | Loss: 0.0706\n",
      "Epoch 068 | Loss: 0.0704\n",
      "Epoch 069 | Loss: 0.0704\n",
      "Epoch 070 | Loss: 0.0704\n",
      "Epoch 071 | Loss: 0.0703\n",
      "Epoch 072 | Loss: 0.0703\n",
      "Epoch 073 | Loss: 0.0703\n",
      "Epoch 074 | Loss: 0.0703\n",
      "Epoch 075 | Loss: 0.0704\n",
      "Epoch 076 | Loss: 0.0705\n",
      "Epoch 077 | Loss: 0.0710\n",
      "Epoch 078 | Loss: 0.0708\n",
      "Epoch 079 | Loss: 0.0712\n",
      "Epoch 080 | Loss: 0.0711\n",
      "Epoch 081 | Loss: 0.0711\n",
      "Epoch 082 | Loss: 0.0707\n",
      "Epoch 083 | Loss: 0.0705\n",
      "Epoch 084 | Loss: 0.0704\n",
      "Epoch 085 | Loss: 0.0704\n",
      "Epoch 086 | Loss: 0.0703\n",
      "Epoch 087 | Loss: 0.0705\n",
      "Epoch 088 | Loss: 0.0707\n",
      "Epoch 089 | Loss: 0.0707\n",
      "Epoch 090 | Loss: 0.0712\n",
      "Epoch 091 | Loss: 0.0711\n",
      "Epoch 092 | Loss: 0.0715\n",
      "Epoch 093 | Loss: 0.0708\n",
      "Epoch 094 | Loss: 0.0705\n",
      "Epoch 095 | Loss: 0.0704\n",
      "Epoch 096 | Loss: 0.0704\n",
      "Epoch 097 | Loss: 0.0704\n",
      "Epoch 098 | Loss: 0.0704\n",
      "Epoch 099 | Loss: 0.0705\n",
      "Epoch 100 | Loss: 0.0704\n"
     ]
    }
   ],
   "source": [
    "# ----- Example Training Loop -----\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_value, weights, bias = update_model(X_gpu, y_gpu)\n",
    "    print(f\"Epoch {epoch + 1:03d} | Loss: {loss_value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
